{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc40283-5e6b-40f3-bec2-a724d2f125b9",
   "metadata": {},
   "source": [
    "This notebook shows how to use the CNN-LSTM model to predict the global temperature map.\n",
    "\n",
    "By Weiwei Zhan\n",
    "\n",
    "Reference: https://github.com/duncanwp/ClimateBench/blob/main/baseline_models/CNN-LTSM_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d96d7efd-6225-4842-a72b-9731c08375ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 01:43:13.372457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Sequential\n",
    "from utils import * \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 400\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams[\"legend.frameon\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc1888e-2d32-4105-a4f0-d5bb8f6a654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_path = \"gs://leap-persistent/jbusecke/data/climatebench/train_val/\"\n",
    "test_path = \"gs://leap-persistent/jbusecke/data/climatebench/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e7aae-9a47-4c34-8d4a-933a4d987714",
   "metadata": {},
   "source": [
    "### 1. data preprocessing: prepare data for training & test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa7b4b-7ea5-4c9f-b410-cbec0e05a9df",
   "metadata": {},
   "source": [
    "#### import data as training & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ad29f1-6cb7-4f9e-b50f-03b01158b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "train_files = [\"historical\", \"ssp585\", \"ssp126\", \"ssp370\",\"hist-GHG\",\"hist-aer\"]\n",
    "X_train_xr, X_length  = prepare_predictor(train_files,train_path)\n",
    "y_train_xr, y_length  = prepare_predictand(train_files,train_path)\n",
    "\n",
    "# Test set\n",
    "X_test_xr, _ = prepare_predictor('ssp245', data_path=test_path,time_reindex=False)\n",
    "y_test_xr, _ = prepare_predictand('ssp245',data_path=test_path,time_reindex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ccacb8-330f-46af-aaac-92edd41aa6c4",
   "metadata": {},
   "source": [
    "#### select relevant variables\n",
    "\n",
    "predictors: CO2, CH4, **SO2, BC (black carbon)** <br/>\n",
    "predictand: tas\n",
    "\n",
    "**Note:** we here include *two additional predictors*: SO2 & BC. SO2 & BC inputs are 2-D maps, while CO2 & CH4 are 1-D time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201fa20b-7de1-4fd9-85d9-996ce950c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = y_train_xr['tas'].data\n",
    "y_test_np  = y_test_xr['tas'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d70eb6-beef-4f5c-ba59-4b4ae22a5af7",
   "metadata": {},
   "source": [
    "#### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a381fc-b055-4993-8c9c-212c69fe6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean/std of each variable for the whole dataset\n",
    "meanstd_inputs = {}\n",
    "predictors     = ['CO2', 'CH4', 'SO2', 'BC']\n",
    "for var in predictors:\n",
    "    meanstd_inputs[var] = (X_train_xr[var].data.mean(),X_train_xr[var].data.std())\n",
    "    \n",
    "# normalize each variables\n",
    "for var in predictors:\n",
    "    # training set\n",
    "    var_dims   = X_train_xr[var].dims\n",
    "    X_train_xr = X_train_xr.assign({var: (var_dims, normalize(X_train_xr[var].data, var, meanstd_inputs))})\n",
    "    \n",
    "    # test set\n",
    "    var_dims  = X_test_xr[var].dims\n",
    "    X_test_xr = X_test_xr.assign({var: (var_dims, normalize(X_test_xr[var].data, var, meanstd_inputs))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c30f54df-909b-4d65-a961-85f46921ccfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753, 96, 144, 4) (753, 96, 144) (86, 96, 144, 4) (86, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "X_train_np = X_train_xr.to_array().transpose('time', 'latitude', 'longitude', 'variable').data\n",
    "X_test_np  = X_test_xr.to_array().transpose('time', 'latitude', 'longitude', 'variable').data\n",
    "\n",
    "print(X_train_np.shape,y_train_np.shape,X_test_np.shape,y_test_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e0103f-95ae-41ee-adfe-1eab05269196",
   "metadata": {},
   "source": [
    "Reshape data to feed into the LSTM model\n",
    "\n",
    "The LSTM needs data with the format of **[samples, time steps, n_latitude, n_longitude, n_features]**\n",
    "\n",
    "Here the lag time step is set to **5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2be1ed7-4d2c-4851-8340-1a6ae899bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.cumsum(X_length) - X_length\n",
    "end   = np.cumsum(X_length)\n",
    "\n",
    "slider = 5\n",
    "n_samples   = X_train_np.shape[0] - (slider-1)*len(X_length)\n",
    "n_lat,n_lon,n_feature = X_train_np.shape[1:]\n",
    "\n",
    "X_train = np.zeros([n_samples,slider,n_lat,n_lon,n_feature])\n",
    "y_train = np.zeros([n_samples,1,n_lat,n_lon])\n",
    "\n",
    "n_start = 0\n",
    "for i in range(len(X_length)):\n",
    "    \n",
    "    X_subset = X_train_np[start[i]:end[i],:]\n",
    "    y_subset = y_train_np[start[i]:end[i],:]\n",
    "    \n",
    "    X_subset = np.array([X_subset[i:i+slider] for i in range(0, X_length[i]-slider+1)])\n",
    "    y_subset = np.array([[y_subset[i+slider-1]] for i in range(0, X_length[i]-slider+1)])\n",
    "    \n",
    "    # print(X_subset.shape,y_subset.shape)\n",
    "    n_length = X_subset.shape[0]\n",
    "    X_train[n_start:n_start+n_length,:,:,:,:] = X_subset\n",
    "    y_train[n_start:n_start+n_length,:,:,:]   = y_subset\n",
    "    n_start += n_length\n",
    "    \n",
    "X_test  = np.array([X_test_np[i:i+slider] for i in range(0, X_test_np.shape[0]-slider+1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1af3aef-d036-4a4b-a24a-12b1db17aa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 5, 96, 144, 4) (729, 1, 96, 144) (82, 5, 96, 144, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aeaa97-1d78-4bf9-b3fc-fd2da1d63b1e",
   "metadata": {},
   "source": [
    "### 2. Define the CNN-LSTM structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522509b5-9ec3-48bf-b4e6-8f994602db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters   = 20 # number of filters\n",
    "kernel_size = 3  # kernel size for Covolutional layers\n",
    "pool_size   = 2  # size for average pooling layers\n",
    "n_lstm_unit = 25 # number of LSTM units\n",
    "activation  = 'relu' # activation function\n",
    "learning_rate = 0.001 # learning rate\n",
    "minibatch_size = 64   # batch size\n",
    "num_epochs     = 50   # number of total epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf79706d-9fe5-4129-9d7a-f66be6278f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 01:44:09.961702: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/nvidia/lib64\n",
      "2023-01-04 01:44:09.961782: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 5, 96, 144, 20)   740       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 5, 48, 72, 20)    0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 5, 20)            0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 25)                4600      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 13824)             359424    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 13824)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 96, 144)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 364,764\n",
      "Trainable params: 364,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(slider, n_lat,n_lon,n_feature)))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (kernel_size, kernel_size), \n",
    "                                     padding='same', activation=activation), input_shape=(slider, n_lat,n_lon,n_feature)))\n",
    "model.add(TimeDistributed(AveragePooling2D(pool_size)))\n",
    "model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
    "model.add(LSTM(n_lstm_unit, activation=activation))\n",
    "model.add(Dense(n_lat*n_lon))\n",
    "model.add(Activation('linear'))\n",
    "model.add(Reshape((1, n_lat, n_lon)))\n",
    "\n",
    "\n",
    "model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c0937-d840-4ec7-ae57-75be756192bb",
   "metadata": {},
   "source": [
    "### 3. Train & save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053e225-dd96-4f2d-b9bf-f46aaa84ad0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 01:44:10.791301: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 644751360 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 32s 3s/step - loss: 3.7926 - val_loss: 0.4796\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 30s 3s/step - loss: 3.5858 - val_loss: 0.5033\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 2.7693 - val_loss: 0.5629\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 30s 3s/step - loss: 1.4718 - val_loss: 0.6446\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.9235 - val_loss: 0.7728\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.6944 - val_loss: 0.9392\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.5408 - val_loss: 1.0502\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.4254 - val_loss: 0.9419\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.3789 - val_loss: 0.7404\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.3579 - val_loss: 0.6874\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.3528 - val_loss: 0.6505\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.3385 - val_loss: 0.6394\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.3308 - val_loss: 0.6097\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.3290 - val_loss: 0.5872\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.3239 - val_loss: 0.5704\n",
      "Epoch 16/50\n",
      " 3/10 [========>.....................] - ETA: 11s - loss: 0.3091"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size = minibatch_size,\n",
    "                    epochs = num_epochs,\n",
    "                    validation_split=0.2, verbose=1,\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a5934-7a3c-423f-970c-1a2f5ffa3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(cwd,'saved_model')\n",
    "make_dir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8119a4-ee17-4a59-b0ee-ae2b1f4c6448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save(os.path.join(model_path,'CNN-LSTM_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e3c4f8-5806-4789-9e6d-7a2c79eb627e",
   "metadata": {},
   "source": [
    "### 4. Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e1ccf-da13-40e3-9e19-a0eba39716d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the saved model\n",
    "model = load_model(os.path.join(model_path,'CNN-LSTM_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629173c-4770-41a6-8638-3d4cf7b80ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pre = model.predict(X_test)\n",
    "y_test_pre = y_test_pre.reshape(y_test_pre.shape[0], 96, 144)\n",
    "y_test_pre = xr.Dataset(coords={'time': X_test_xr.time.values[slider-1:], \n",
    "                               'latitude': X_test_xr.latitude.values, \n",
    "                               'longitude': X_test_xr.longitude.values},\n",
    "                       data_vars=dict(tas=(['time', 'latitude', 'longitude'], y_test_pre)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9de794-15f1-43f3-b33f-b7dd9a4fbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15,12),ncols=2,nrows=3)\n",
    "\n",
    "yrs = [2030, 2050, 2100]\n",
    "vmin, vmax    = -6, 6\n",
    "cmap = 'RdBu_r'\n",
    "y_test_pre.tas.sel(time=yrs[0]).plot(ax=axes[0,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[0]).plot(ax=axes[0,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[1]).plot(ax=axes[1,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[1]).plot(ax=axes[1,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[2]).plot(ax=axes[2,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[2]).plot(ax=axes[2,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # left column: model prediction\n",
    "    if i % 2 == 0:\n",
    "        ax.set_title(f'tas model prediction (year = {yrs[i//2]})',fontweight='bold')\n",
    "    # right column: truth tas from ssp245 simulations\n",
    "    else:\n",
    "        ax.set_title(f'tas truth (year = {yrs[i//2]})',fontweight='bold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac492530-31d2-488a-8c64-3dbf5a2249a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2758bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
